# Parallelise pipelines

Parallelised pipelines allow for the automatic replication of a pipeline along a
predefined parameter space to reuse nodes and aid parallel execution.

The parameters either received in the replicated node's functions as keyword
arguments or used to filter some of the input datasets for the given pipeline
replica by filtering them along specified columns.

The parameter space could be a combination of multiple scenarios, where
- each scenario has it possible values predefined
- each senario has its unique parameter or filtering column
- the pipeline is replicated for all the possible combination of the scenarios (Cartesian product)

<details>
<summary><b>Click to expand</b></summary>


```python
new_pipe = parallelised_pipeline(
    pipe,
    scenarios={"scenario1": ["A", "B"], "scenario2": ["c", "d"]},
)
```
</details>

The above code replicates the original pipeline 4 times and adds a synthetic
node for aggregation of the results of each replicated sub-pipeline.

All the sub-pipelines and the synthetic node return as a new pipeline, that
could run the same way as the original and produce the same result just
organized in a way significantly more suitale for parallelisation without
significantly modifying the node level functions.

In the above setup the node functions need to be able to accept two additional
keyword arguments: `scenario1` and `scenario2`. These arguments are added to
the original function with the help of `functools.partial`.

By using dataset filtering option the original node functions does not need any
modification.

<details>
<summary><b>Click to expand</b></summary>


```python
new_pipe = parallelised_pipeline(
    pipe,
    scenarios={
        "scenario1": ["A", "B"],
        "scenario2": ["c", "d"],
    },
    filters={"base_data": ["col1", "col2"]},
)
```
</details>

In this usage the dataset named `base_data` will be filtered for the given
scenario value combination relevant for the given pipeline replica by the
columns specified in order of the scenarios, `col1` and `col2` in the example.
That means, that for the combinaton `("A", "d")` the base data will be filtered
by `col1` where `col1 == "A"` and by `col2` where `col2 == "d"`. If the filtering
produces an empty dataset a wraning is generated.

The filtered datasets are generated by another synthetic node and aliased for the
given sub-pipeline, the same way as all the nodes and datasets are aliased for
the pipeline replicas using the namespace functionality of the
[modular pipelines](./03_modular_pipelines.md)
